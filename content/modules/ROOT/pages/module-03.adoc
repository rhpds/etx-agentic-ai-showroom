:imagesdir: ../assets/images
= From Playground to Prototype - Building Your Agent in Red Hat AI

include::vars.adoc[]

[IMPORTANT]
.In this lab
====
You will build an agent, and manage it through ArgoCD. You will then create a pipeline to trigger the agent to create a GitHub issue in your forked repository from previous modules.
====

== Git clone repository locally

In your own environment, or in your showroom terminal if preferred:

. Authenticate to the cluster with your user credentials.
. Clone your previously created repository fork:
+
[source,bash,options="wrap",role="execute"]
----
cd ${DESIRED_DIRECTORY_LOCATION}
git clone https://github.com/[YOUR-GITHUB-ID]/etx-agentic-ai-gitops.git
cd etx-agentic-ai-gitops
----
+
. Authenticate to github, if not already, using a personal access token (separate from the one previously created in the workshop) with at least `Read and Write` permission to `Contents` of the above repository.

== Load the Agent files

. In your local preferred environment, or within the workbench image IDE, open `agent/code/agent.py` and view the contents of the agent application. This file contains the core logic. Ensure you understand how it works. Then view the `agent/code/main.py` file to understand how the agent is triggered.

Overall, the system works as a GitOps remediation / failure triage agent:

* FastAPI server receives failure notifications
* Agent analyzes OpenShift pod logs using MCP tools
* Searches for solutions via web search
* Creates GitHub issues with error summaries and solutions

// changes to file including your github user id, username

. Git commit and push changes to your fork.

== Trigger pipeline to build the agent image

. In your chosen terminal environment, create a PipelineRun using the following command:

NOTE: Edit the file in the below command with the appropriate variables. Then, ensure the forked repository location is accurate in the command.

[source,bash,options="wrap",role="execute",subs="attributes+"]
----
oc -n {etx_agentic_ai_username}-ai-agent create -f etx-agentic-ai-gitops/lab-resources/agent-service-build-run
----

. View the pipelinerun status either in the UI or by command:
+
[source,bash,options="wrap",role="execute",subs="attributes+"]
----
# List all PipelineRuns to find the generated name
oc -n {etx_agentic_ai_username}-ai-agent get pipelineruns
# Watch the PipelineRun status
oc -n {etx_agentic_ai_username}-ai-agent get pipelineruns -w
----

== Deploy the agent with ArgoCD

. In your chosen terminal, with your preferred editor, edit the `values.yaml` file found in `etx-agentic-ai-gitops/agent/chart/`

+
[source,bash,options="wrap",role="execute"]
----
vim etx-agentic-ai-gitops/agent/chart/values.yaml
----
+

. Replace the values for [YOUR_USER_NUMBER] and [YOUR_GITHUB_USERNAME] as shown in the example below:

[source,yaml,options="wrap",role="execute"]
----
namespace: user1-ai-agent
registry: image-registry.openshift-image-registry.svc:5000
application_name: ai-agent

# Agent Configuration
agentConfig:
  clientTimeout: "600.0"
  llamaStackUrl: "http://user1-llama-stack-service.user1-llama-stack.svc.cluster.local:8321"
  maxInferIterations: "50"
  maxTokens: "5000"
  modelId: "granite-3-2-8b-instruct"
  temperature: "0.0"
  githubOwner: "github_username"
----

. Edit the variables within the `etx-agentic-ai-gitops/lab-resources/ai-agent-app file. For namespace set `{etx_agentic_ai_username}-ai-agent` and for GitHub repository set your forked repo location.

. Create a new argo application from your command line with the following command (you may choose to create the app via the UI as well if you prefer).
+
[source,bash,options="wrap",role="execute"]
----
oc apply -f etx-agentic-ai-gitops/lab-resources/ai-agent-app
----

=== Check on application with CLI or ArgoCD UI

[source,bash,options="wrap",role="execute"]
----
oc get apps -o wide
----

. Get route for user-scoped argo instance:

[source,bash,options="wrap",role="execute"]
----
oc -n user{your-user-number}-ai-agent get routes
----

or in the UI:

image::../assets/images/argo-route.png[]

. Verify health of app and associated agent pod running

== Test your agent's function with a demonstrative pipeline

We will now test the MCP and model integrations, which we've tested already via the playground (as designed!) in the context of your new agent that we've just deployed.

This demo application pipeline models a common CI/CD flow and adds an automated recovery aid:

* Fetch source: git-clone pulls your repo and revision

* Build image: buildah builds and pushes the container image

* Deploy: oc rollout status verifies the deployment

* Finally: On failure, a finally step triggers the agent service with pod context.

=== Apply the pipeline resource

Using your terminal or the (+) button in the web console, apply the following pipeline resource with your user number substituted into the metadata/namespace placeholder (you will need to edit the file directly):

[source,yaml,options="wrap",role="execute"]
----
oc apply -f etx-agentic-ai-gitops/lab-resources/demo-pipeline
----

=== Trigger the pipeline

Since the pipeline is configured to fail by default (using `GIT_REVISION: bad`), you can trigger it with minimal parameters. Only `NAMESPACE` is required since it has no default.

. Create the PipelineRun:
+
[source,bash,options="wrap",role="execute"]
----
oc -n {etx_agentic_ai_username}-ai-agent create -f etx-agentic-ai-gitops/lab-resources/demo-pipeline-run
----

. Monitor the PipelineRun:
+
[source,bash,options="wrap",role="execute",subs="attributes+"]
----
oc -n user${YOUR_USER_NUMBER}-ai-agent get pipelineruns -w
----
+

The pipeline will fail on the build step, which will trigger the `finally` step which calls the agent service to analyze the failure and create a GitHub issue.

. Confirm pipelinerun detailed failure:
+
[source,bash,options="wrap",role="execute"]
----
oc get taskrun -l tekton.dev/pipelineRun=java-app-build-run-{UNIQUE_ID}
----
+
. Verify in your forked repository that the issue was successfully generated.


== Whatâ€™s Next

With the agent running as a service and integrated with the pipeline trigger, you have the foundation for a production rollout. You are now setup for a scenario where you have a new ticket coming in and you need to update your agent and your MTTR is fast due to the automation. Perhaps you are event adventurous enough to add the agent tooling itself as a `finally` call in your agent build pipeline to catch and resolve errors quickly. We will not be doing that today, so that will be left to the reader, but in the next module, we will discuss hardening, observability, and promotion flows.

== Next Steps

With your agent now running as a service and integrated with the pipeline trigger, you have established the foundation for a production-ready workflow. This setup enables rapid response to failures, as new issues are automatically created in your GitHub repository, reducing mean time to resolution (MTTR).

In the next module, you will learn how to further harden your deployment, add observability, and implement promotion flows to ensure your agent remains robust and reliable as you move toward production.