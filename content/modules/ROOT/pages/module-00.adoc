= Lab Setup and Prerequisites

[NOTE]
====
Persona: Platform Engineer (primary). Also relevant: AI Engineer.
====

[NOTE]
====
Estimated time: 30 minutes
====

== What you'll do

* Verify cluster access and bootstrap GitOps
* Fork the repo, set PATs and webhooks
* Ensure Console Links and core apps are healthy

== Prerequisites

Before starting this lab, ensure you have the following:

=== Required Tools

* **GitHub Account**: You'll need access to fork repositories and collaborate
* **Git CLI**: Installed and configured on your local machine
* **OpenShift CLI (oc)**: Download from https://mirror.openshift.com/pub/openshift-v4/clients/ocp/[OpenShift client downloads,window=_blank]
* **jq**: Command-line JSON processor for parsing command outputs
* **Python 3**: Provides `json.tool` for pretty-printing JSON
* **envsubst (gettext)**: For environment variable substitution in manifests
* **Terminal/Command Line**: Bash shell with basic utilities (openssl, curl)
* **Ansible Vault**: Part of Ansible toolkit for secret management
* **Web Browser**: For accessing OpenShift console, MaaS portal, and documentation

=== Required Skills
* **Basic Git Knowledge**: Cloning repositories, basic version control concepts
* **Command Line Basics**: Navigating directories, running commands
* **Container Concepts**: Understanding of containers and Kubernetes/OpenShift (helpful but not required)

=== Provided by Instructors
* **OpenShift Cluster Access**: Admin credentials
* **Red Hat MaaS Access**: Model-as-a-Service credentials for LLaMA models
* **Workshop Materials**: All necessary configuration files and scripts
* **Environment Variables**: Cluster-specific configuration values
* **Support**: Technical assistance throughout the lab

== Getting Started

Before diving into the agentic AI lab, we need to set up our development environment. This involves:

* **Setting up GitOps**: Configure automated deployment pipelines that manage our infrastructure and applications

[IMPORTANT]
====
**For this lab**: We have used automated https://github.com/rhpds/etx-llmaas-gitops[bootstrap scripts,window=_blank] to handle the setup quickly so we can focus on building AI agents.
====

**For later exploration** (after the lab):

* **Manual setup**: The step-by-step instructions below show how each component works - perfect for understanding GitOps and secret management in detail

== Initial Setup

. **Receive your cluster credentials** ðŸ”
+
Your instructor will provide OpenShift login credentials for your cluster.

. **Set up your shared repository**:
.. https://github.com/redhat-ai-services/etx-agentic-ai[Fork the etx-agentic-ai repository,window=_blank] to your personal GitHub account
+
.GitHub Repo Fork
image::github-fork.png[GitHub Repo Fork, 400]
+

.. Ensure that you **Enable Issues** for your fork under **Settings** > **General** > **Features** > **Issues** as they are disabled for forked repos by default
+
.GitHub Repo Enable Issues
image::github-repo-enable-issues.png[GitHub Repo Enable Issues, 400]

. **Setup and run the Web Terminal Operator as described in the Quick Starts**

. **Later in the lab we will clone the forked repository to the OpenShift Web Terminal through steps in the Quick Starts, but if you're running the lab locally you can go ahead and clone the repository locally to your laptop.**
+
[source,bash,options="wrap",role="execute"]
----
git clone git@github.com:your-gh-user/etx-agentic-ai.git
cd etx-agentic-ai
----
+
.GitHub Repo Clone
image::github-clone.png[GitHub Repo Clone, 400]
+
[TIP]
====
Replace `your-gh-user` with the actual GitHub username of whoever forked the repository.
====

. **Verify your setup** âœ…
+
You should now have:
+
* Access to your OpenShift cluster
* A fork of the repository
* Local copies of the code

== Cluster Environment

You have now access to a fully-featured OpenShift cluster designed for AI workloads. This cluster mimics many customer production environments. Here's how the platform is architected:

=== Bootstrap Components
These foundational components are deployed first to establish the platform's operational baseline:

* **Red Hat OpenShift**: Enterprise Kubernetes platform providing container orchestration
* **Argo CD**: Declarative, Git-driven application deployments
* **OpenShift Secrets**: Secure credential storage and automated secret injection

=== Security, Governance, and Delivery (Argo CD + Policy as Code)
Built on the bootstrap foundation, we combine continuous delivery with continuous compliance:

[IMPORTANT]
.Why both exist in this repo
====
* **Argo CD (delivery)** deploys the capabilities that teams need (Llama Stack, MCP tools, agent services, pipelines) from Git
* **Policy as Code (governance)** enforces the rules those capabilities must follow (security, sources, sizes, hygiene)

What policies can assert here:

* **Model source allowlists**: only approved providers/endpoints (legal/commercial constraints)
* **Model size limits**: keep parameter/VRAM footprint within cost/perf targets
* **Image/registry restrictions**: approved registries and signed images
* **Resource hygiene**: every Pod declares requests/limits; GPU workloads use time-slicing/quotas
* **Secret handling**: Vault or external secret injection; no plaintext k8s secrets
* **Network posture**: NetworkPolicies limiting egress to approved services (e.g., Llama Stack, GitHub MCP)

This pairing yields:

* **Zero Configuration Drift**: what's in Git is what runs (Argo CD)
* **Automated Compliance**: guardrails are applied continuously (policies)
* **Green from GO**: start compliant; learn inside enterprise guardrails from day one

NOTE: Policy as Code is not strictly required to complete this lab. It is, however, a highly useful paradigmâ€”and in some environments or delivery workflows it is requiredâ€”so we model it here to reflect real-world practices.

Learn more:

* https://open-cluster-management.io/docs/getting-started/integration/policy-controllers/policy/[Policy API Concepts,window=_blank]
* https://github.com/open-cluster-management-io/policy-collection[Policy Collection,window=_blank]
* https://github.com/open-cluster-management-io/policy-generator-plugin[Policy Generator,window=_blank]
====

.Policy as Code using GitOps and ACM
image::policy-as-code.png[Policy as Code, 600]

=== Developer Platform Services
Self-service capabilities that enable development teams:

* **CI/CD Pipelines**: Tekton for automated container builds, testing, and deployments
* **Source Control Integration**: Git-based workflows with automated quality gates
* **Container Registry**: Secure image storage with vulnerability scanning and promotion workflows

=== Tenant & Workload Services
Multi-tenant capabilities providing isolated, secure environments:

* **Namespace Management**: Multi-tenant isolation with RBAC and resource quotas
* **Development Workbenches**: Self-service Jupyter environments for data science teams
* **Service Mesh**: Secure service-to-service communication and traffic management

=== AI/ML Platform Services
Specialized services for AI/ML workloads and agentic applications:

* **Red Hat OpenShift AI (RHOAI)**: Managed AI/ML platform with GPU acceleration
* **Model Serving Infrastructure**: Scalable inference endpoints with model lifecycle management
* **Agentic AI Runtime**: Environment for deploying AI agents with external service integrations

[TIP]
====
**LLaMA Stack Integration**: Our agentic AI workloads leverage https://github.com/llamastack/llama-stack[LLaMA Stack,window=_blank], a composable framework that provides standardized APIs for model inference, safety guardrails, and tool integration. This allows our AI agents to seamlessly interact with large language models while maintaining consistent interfaces for memory management, tool calling, and safety controls across different model providers.
====

**The Benefits:**

* **ZERO configuration drift** - what's in git is real
* **Integrates into the Governance Dashboard in ACM for SRE**
* **We start as we mean to go on** - we are Green from GO so that our dev environment looks like prod only smaller
* **All our clusters and environments are Kubernetes Native once bootstrapped**

== Required Applications

You need to do each of these Prerequisites.

. We **Recommend** using the **Quick Starts** initially, then your laptop after the initial setup.
+
Start with the **Quick Start** - **ETX 1 The Basics**

. You may choose another client to bootstrap from (not recommended **especially** if you are on **MacOSX** which is not fully tested). It could be:
** Your https://www.dell.com/en-au/shop/dell-laptops/xps-16-laptop/spd/xps-16-9640-laptop[Laptop,window=_blank] or a https://docs.fedoraproject.org/en-US/fedora-silverblue/toolbox[Toolbx,window=_blank] or a https://docs.fedoraproject.org/en-US/docs/[Fedora like jumphost,window=_blank] or a https://docs.redhat.com/en/documentation/red_hat_openshift_ai_cloud_service/1/html/working_on_data_science_projects/using-project-workbenches_projects#creating-a-project-workbench_projects[Workbench Terminal,window=_blank] that can access your cluster and the internet
** Your bootstrap client must have a https://packages.fedoraproject.org/pkgs/bash/bash/[bash,window=_blank] shell with https://packages.fedoraproject.org/pkgs/openssl/openssl/[openssl,window=_blank], https://docs.ansible.com/ansible/2.9/cli/ansible-vault.html#ansible-vault[ansible-vault,window=_blank] installed
** Login to your OpenShift cluster using the https://mirror.openshift.com/pub/openshift-v4/clients/ocp/[OpenShift client,window=_blank] as the cluster-admin user

. Setup env vars and login to OpenShift. You can either use the OpenShift Web Console to grab a login command or use the details below to construct the login command on your own.
+
TIP: Covered in a Quick Start
+
[source,bash,options="wrap",role="execute"]
----
export ADMIN_PASSWORD=password # replace with yours
export CLUSTER_NAME=ocp.4ldrd # replace with yours
export BASE_DOMAIN=sandbox2518.opentlc.com # replace with yours
----
+
[source,bash,options="wrap",role="execute"]
----
oc login --server=https://api.${CLUSTER_NAME}.${BASE_DOMAIN}:6443 -u admin -p ${ADMIN_PASSWORD}
----

. Done âœ…

=== MaaS credentials

[NOTE]
====
This whole section can be skipped unless you wish to use your own Model as a Service Credentials. We will share the provided credentials to save time.

Gather your Model as a Service Credentials.

. Login to https://maas.apps.prod.rhoai.rh-aiservices-bu.com[Models-as-a-service using your RedHat credentials,window=_blank].
. Click on the __See your Applications & their credentials__ button.
. Create 3 Applications for these three models
** **Llama-3.2-3B**
** **Llama-4-Scout-17B-16E-W4A16**
** **Nomic-Embed-Text-v1.5**
+
e.g. for example __llama-4-scout-17b-16e-w4a16__
+
.MaaS LLama4 Scout
image::maas-llama-4-scout-17b-16e-w4a16.png[MaaS LLama4 Scout, 400]

. Setup env vars
+
[source,bash,options="wrap",role="execute"]
----
export MODEL_LLAMA3_API_KEY=e3...
export MODEL_LLAMA3_ENDPOINT_URL=https://llama-3-2-3b-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443
export MODEL_LLAMA3_NAME=llama-3-2-3b

export MODEL_LLAMA4_API_KEY=ce...
export MODEL_LLAMA4_ENDPOINT_URL=https://llama-4-scout-17b-16e-w4a16-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443
export MODEL_LLAMA4_NAME=llama-4-scout-17b-16e-w4a16

export MODEL_EMBED_API_KEY=95...
export MODEL_EMBED_URL=https://nomic-embed-text-v1-5-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443
export MODEL_EMBED_NAME=/mnt/models
----

. Done âœ…
====

=== Tavily search token

Gather your Tavily web search API Key.

. Setup a https://app.tavily.com[Tavily,window=_blank] api key for web search. Login using a github account of one of your team members.
+
.Tavily API Key
image::tavily-apikey.png[Create Tavily API Key, 600]

. Done âœ…

=== GitHub Token

Create a fine-grained GitHub Personal Access (PAT) Token.

. Login to GitHub in a browser, then click on your user icon > **Settings**

. Select **Developer Settings** > **Personal Access Tokens** > **Fine-grained personal access tokens**

. Select Button **Generate a new token** - give it a token name e.g. __etx-ai__

. Set **Repository access**
+
**All repositories**: allow access to your repositories including read-only public repos.

. Give it the following permissions:
+
**Commit statuses**: Read-Only
+
**Content**: Read-Only
+
**Issues**: Read and Write
+
**Metadata**: Read-Only (this gets added automatically)
+
**Pull requests**: Read-Only
+
.GitHub Repo Perms
image::github-repo-perms.png[GitHub Repo Perms, 400]

. Generate the token.
+
.GitHub Repo Token
image::github-pat.png[GitHub Repo Token, 400]

. Done âœ…

=== GitHub Webhook

Create a webhook that fires from your GitHub repo fork to Argo CD on the OpenShift Cluster. This ensures the applications are synced whenever you push a change into git (rather than wait the 3min default sync time).

. Login to GitHub in a browser, go to your **etx-agentic-ai** fork > **Settings**

. Select **Webhooks**

. Select **Add Webhook**. Add the following details
+
**Payload URL:** https://global-policy-server-openshift-policy.CLUSTER_DOMAIN/api/webhook - You can get the correct URL by echoing this out on the command line:
+
[source,bash,options="wrap",role="execute"]
----
echo https://global-policy-server-openshift-policy.CLUSTER_DOMAIN/api/webhook
----
+
**Content Type:** application/json
+
**SSL Verification:** Enable SSL Verification
+
**Which events:** Send me everything

. Click **Add Webhook**
+
.GitHub Webhook
image::github-webhook.png[GitHub Webhook, 400]

. Done âœ…

== Complete the Bootstrap

. The following https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/console_apis/consolelink-console-openshift-io-v1[OpenShift ConsoleLinks,window=_blank] should already exist in your cluster:
+
image::add-console-links.png[Console Links, 300]
+
**Red Hat Applications** - these are cloud services provided by Red Hat for your cluster.
+
**GenAI** - these are the GenAI applications that we will be using in the exercises. The **Agentic Argo CD** should be running but is empty (no apps deployed yet) and is our GitOps application. The **LLamaStack Playground** is not deployed yet, but will be the link for the LlamaStack UI for integrating Tools and Agents. **Vault** is running and initialized and unsealed and is the app that stores our secrets.
+
**OpenShift GitOps** - this is the cluster bootstrap Argo CD GitOps. This has all of the setup to get started for our cluster. It does not include the Agentic applications that we cover in the exercises.
+
**RHOAI** - the UI for Red Hat OpenShift AI. Login here to access your Data Science workbenches, models, pipelines and experiments.

. Bootstrap https://argo-cd.readthedocs.io/en/latest/operator-manual/cluster-bootstrapping/#app-of-apps-pattern[App-of-Apps,window=_blank]
+
[source,bash,options="wrap",role="execute"]
----
# We need to update our Argo CD Apps to point to your team fork
export YOUR_GITHUB_USER=your-gh-user  # the Team member who forked the GitHub Repo
cd etx-agentic-ai   # Navigate to root directory of code base if not already there
----

. Replace the `redhat-ai-services` throughout the file with your GitHub username.
+
[source,bash,options="wrap",role="execute"]
----
sed -i "s/redhat-ai-services/${YOUR_GITHUB_USER}/g" infra/app-of-apps/etx-app-of-apps.yaml
----

. Update the `redhat-ai-services` to your GitHub username in the `etx-app-of-apps.yaml` file.
+
[source,bash,options="wrap",role="execute"]
----
for x in $(ls infra/app-of-apps/sno); do
    sed -i "s/redhat-ai-services/${YOUR_GITHUB_USER}/g" infra/app-of-apps/sno/$x
done
----

. Now we can save, commit, and push the changes to your GitHub fork.
+
[source,bash,options="wrap",role="execute"]
----
# Its not real unless its in git
git add .; git commit -m "using my github fork"; git push
----

. Finally, we can bootstrap the apps into our cluster.
+
[source,bash,options="wrap",role="execute"]
----
# Bootstrap all our apps
oc apply -f infra/app-of-apps/etx-app-of-apps.yaml
----
+
This will install the tenant pipeline app and observability stack into our cluster. All the other GenAI apps are undeployed for now. You can check this in your _app-of-apps/cluster-name_ github fork folder.
+
image::bootstrap-initial.png[bootstrap-initial, 400]

. Check the Install progress of the app-of-apps in the **Agentic Argo CD**
+
image::bootstrap-begin.png[bootstrap-begin, 400]

. You will need to wait for the individual apps to be installed. This may take a few minutes. After a few minutes, you should see the following output to show that the apps have been installed.
+
image::bootstrap-complete.png[bootstrap-complete, 400]
+
Also, notice that the `tenant-ai-agent-local-cluster` app is constantly in a progressing state. This is something we will address later in this course.

. Done âœ…

== Technical Knowledge

Ideally https://www.redhat.com/tracks/_pfcdn/assets/10330/contents/344388/925d2cb5-39c2-49dc-9ed2-3f4aeeb52a85.pdf[your team is a cross-functional one (Optional: Read Chapter.1 - Introduction),window=_blank] with:

* Good understanding of OpenShift/Kubernetes concepts
* Basic familiarity with Python programming
* Good knowledge of https://www.redhat.com/en/topics/containers[containerization,window=_blank] concepts
* Basic understanding of CI/CD pipelines
* Good grasp of https://openpracticelibrary.com/practice/gitops[GitOps,window=_blank] and https://openpracticelibrary.com/practice/everything-as-code[Everything as Code practices,window=_blank]

xref:module-01.adoc[â˜• Buckle Up], Here we go ...

// lightbox - for images - FIXME need to make the include::partial$lightbox.hbs WORK
++++
<div id="myModal" class="modal">
    <span class="close cursor" onclick="closeModal()">&times;</span>
    <div class="modal-content" onclick="closeModal()">
        <!--suppress HtmlRequiredAltAttribute as this will be set when selecting the image via JavaScript,
        RequiredAttributes as src will be set by when selecting the image via JavaScript -->
        <img id="imageinmodal">
    </div>
</div>
<script>
    function openModal() {
        document.getElementById("myModal").style.display = "block";
        // use overflowY = hidden to prevent the body from scrolling when modal is visible
        // doesn't work with overscroll-behavior, as this would work only when the modal has a scrollbar
        document.getElementsByTagName("body")[0].style.overflowY = "hidden";
    }

    function closeModal() {
        document.getElementById("myModal").style.display = "none";
        document.getElementsByTagName("body")[0].style.overflowY = "auto";
    }

    document.querySelectorAll('.imageblock img').forEach(element => {
        if (element.closest('a') === null) {
            element.className += " lightbox";
            element.addEventListener('click', evt => {
                document.getElementById("imageinmodal").setAttribute("src", evt.currentTarget.getAttribute("src"))
                document.getElementById("imageinmodal").setAttribute("alt", evt.currentTarget.getAttribute("alt"))
                openModal();
            })
        }
    });
</script>
<style>
    /* The Modal (background) */
    .modal {
        display: none;
        position: fixed;
        z-index: 10;
        padding-top: 5vh;
        left: 0;
        top: 0;
        width: 100%;
        height: 100%;
        overflow: auto;
        backdrop-filter: blur(3px);
        background-color: rgba(30, 30, 30, 0.8);
    }
    img.lightbox {
        cursor: pointer;
    }
    /* Modal Content */
    .modal-content {
        position: relative;
        margin: auto;
        padding: 0;
        width: 90%;
        max-height: 90vh;
        cursor: pointer;
    }

    .modal-content img {
        width: auto;
        height: auto;
        max-width: 90vw;
        max-height: 90vh;
        min-width: 90vw;
        min-height: 90vh;
        display: block;
        margin-right: auto;
        margin-left: auto;
        object-fit: contain;
    }

    /* The Close Button */
    .close {
        color: white;
        position: absolute;
        top: 10px;
        right: 25px;
        font-size: 35px;
        font-weight: bold;
    }

    .close:hover,
    .close:focus {
        color: #999;
        text-decoration: none;
        cursor: pointer;
    }
</style>
++++
